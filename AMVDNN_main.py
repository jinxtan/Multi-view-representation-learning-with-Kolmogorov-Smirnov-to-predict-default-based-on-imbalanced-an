# -*- coding: utf-8 -*-"""Created on 2022/9/20 11:48@author: Jinxtanemail: tanyd20@fudan.edu.cnPyCharm.py"""from multi_view_representation import *import warningsfrom models import multi_view_learningimport tensorflow as tffrom index_function import *from utils import lr_schedulefrom plot_curve import *import matplotlib.pyplot as pltfrom sklearn.metrics import classification_reportimport numpy as npimport oswarnings.filterwarnings('ignore')config = tf.compat.v1.ConfigProto()config.gpu_options.allow_growth = Truesession = tf.compat.v1.Session(config = config)# data preparationyear = 2019data = pd.read_csv('data_' + str(year) + '.csv')del data['Unnamed: 0']del data['issue_d']data = (data - data.min()) / (data.max() - data.min())header_name = data.columns.values.tolist()# Delete the column with only one type of valueclass_n = []for i in header_name:	class_n.append(len(data[i].unique()))	if len(data[i].unique()) == 1:		data = data.drop(i,axis = 1)# Sample 80% 0 class samplesdata_no = data[data['loan_status'] == 1]data_ok = data[data['loan_status'] == 0].sample(frac = 0.8,replace = True,random_state = 5,axis = 0)data = pd.concat((data_ok,data_no),axis = 0)y = data['loan_status'].valuesdel data['loan_status']X = data.values# Training parametersweights = 0.8batch_size = 300epochs = 80train_x,test_x,train_y,test_y = train_test_split(X,y,stratify = y,random_state = 50,test_size = 0.3)test_x,val_x,test_y,val_y = train_test_split(test_x,test_y,stratify = test_y,random_state = 50,test_size = 0.5)# multi-view representation waymulti_view = 'AMV'if multi_view == 'AMV':	train_x,train_y,test_x,test_y,val_x,val_y,p_li,n_li,p_lf,n_lf = \		multi_view_AMV(train_x,test_x,train_y,test_y,val_x,val_y,header_name,class_n)if multi_view == 'Kmeans':	train_x,train_y,test_x,test_y,val_x,val_y,p_li,n_li,p_lf,n_lf = \		multi_view_Kmeans(train_x,test_x,train_y,test_y,val_x,val_y,header_name,class_n)x0 = len(p_li)x1 = len(n_li)x2 = len(p_lf)x3 = len(n_lf)# Input data dimensions.input_shape = train_x.shape[1:]num_classes = 2# Convert class vectors to binary class matrices.y_train = tf.keras.utils.to_categorical(train_y,num_classes)y_test = tf.keras.utils.to_categorical(test_y,num_classes)model = DNN_Attention.dnn_v1(input_shape = input_shape,num_classes = num_classes,							 x0 = x0,x1 = x1,x2 = x2,x3 = x3)if year == 2018:	lr = 0.2elif year == 2019:	lr = 0.3# set KS as one learn monitoring metrics for assisting in the discrimination of the unbalanced samplesmodel.compile(loss = 'binary_crossentropy',			  optimizer = tf.keras.optimizers.Adam(lr = lr),			  metrics = ['accuracy',ks_()])model.summary()indicators = 'ks'# Prepare model model saving directory.model_name = 'finance_%s_model.hdf5'filepath = os.path.join('saved_models',model_name)checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath,verbose = 2,save_best_only = True)# Prepare callbacks for model saving and for learning rate adjustment.callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_' + indicators),			 tf.keras.callbacks.EarlyStopping(patience = 15,monitor = 'val_' + indicators),			 tf.keras.callbacks.ModelCheckpoint(filepath = filepath,monitor = 'val_' + indicators,save_best_only = True,												verbose = 1)]# Run training, with or without data augmentation.Training = model.fit(x = train_x,y = y_train,					 batch_size = batch_size,epochs = epochs,					 validation_data = (test_x,y_test),					 shuffle = True,callbacks = callbacks)# Score trained model.model = tf.keras.models.load_model(filepath,custom_objects = {'ks': ks_()})scores = model.evaluate(test_x,y_test,verbose = 1)y_score = model.predict(val_x)y_pred = np.argmax(model.predict(val_x),axis = 1)print('Test loss:',scores[0])print('Test accuracy:',scores[1])result = classification_report(val_y,y_pred)print(result)auc = roc_auc_score(val_y,y_score[:,1])  #i = 1plt.figure(i)i = i + 1KS_curve(y_score[:,1],val_y,10,0,i)plt.show()plt.figure(i)i = i + 1loss_curve(Training,multi_view)plt.show()plt.figure(i)i = i + 1acc_curve(Training,multi_view)plt.show()plt.figure(i)KS_train_curve(Training,multi_view)plt.show()